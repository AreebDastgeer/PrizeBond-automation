{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d327e694-2da5-4251-92a6-5b782896a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "\n",
    "BASE_URL = \"https://savings.gov.pk/rs-750-prize-bond-draw/\"\n",
    "DOWNLOAD_DIR = \"results\"\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "def download_txt_files():\n",
    "    response = requests.get(BASE_URL)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find all <a> tags that point to .txt files\n",
    "    links = soup.find_all(\"a\", href=re.compile(r'\\.txt$'))\n",
    "\n",
    "    for link in links:\n",
    "        file_url = link['href']\n",
    "        file_name = file_url.split(\"/\")[-1]\n",
    "        save_path = os.path.join(DOWNLOAD_DIR, file_name)\n",
    "\n",
    "        try:\n",
    "            r = requests.get(file_url)\n",
    "            r.raise_for_status()\n",
    "            with open(save_path, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "            print(f\"‚úÖ Downloaded: {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to download {file_url}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    download_txt_files()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58249a2c-de6d-4790-b200-bd2428763b8b",
   "metadata": {},
   "source": [
    "## Match Bond Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e440e-8978-4bec-a9b3-c10476d938be",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                     \n",
    "import os\n",
    "import re\n",
    "\n",
    "def load_bonds(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return set(line.strip() for line in file if re.fullmatch(r'\\d{6}', line.strip()))\n",
    "\n",
    "def extract_bond_numbers(file_content):\n",
    "    return set(re.findall(r'\\b\\d{6}\\b', file_content))\n",
    "\n",
    "def check_results(bond_file, results_dir='bond_results'):\n",
    "    your_bonds = load_bonds(bond_file)\n",
    "    winners = {}\n",
    "\n",
    "    for file_name in os.listdir(results_dir):\n",
    "        if not file_name.endswith(\".txt\"):\n",
    "            continue\n",
    "        \n",
    "        file_path = os.path.join(results_dir, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        draw_numbers = extract_bond_numbers(content)\n",
    "        matched = your_bonds & draw_numbers                                        \n",
    "  \n",
    "  \n",
    "        \n",
    "        if matched:\n",
    "            winners[file_name] = matched\n",
    "\n",
    "    return winners\n",
    "\n",
    "# --- RUN ---\n",
    "if __name__ == \"__main__\":\n",
    "    result = check_results(\"my_bonds.txt\")\n",
    "\n",
    "    if result:\n",
    "        print(\"üéâ Winning bonds found:\\n\")\n",
    "        for draw_file, bonds in result.items():\n",
    "            print(f\"üìÑ {draw_file}:\")\n",
    "            for bond in sorted(bonds):\n",
    "                print(f\"   üèÜ {bond}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"üôÉ No winning bonds found in any draw files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57e4112-04f7-400f-8679-1e36a771907c",
   "metadata": {},
   "source": [
    "### For downloading doc file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db16b4-72d9-4bd7-8a15-731ad90e72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from pathlib import Path\n",
    "from docx import Document\n",
    "\n",
    "# Setup\n",
    "BASE_URL = \"https://savings.gov.pk/rs-750-prize-bond-draw/\"\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Supported extensions\n",
    "extensions = ['.txt', '.docx']  # .doc skipped for now\n",
    "\n",
    "def convert_docx_to_txt(docx_path, txt_path):\n",
    "    try:\n",
    "        doc = Document(docx_path)\n",
    "        with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "            for para in doc.paragraphs:\n",
    "                f.write(para.text + '\\n')\n",
    "        print(f\"‚úÖ Converted: {docx_path.name} ‚Üí {txt_path.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to convert {docx_path.name}: {e}\")\n",
    "\n",
    "# Fetch and parse webpage\n",
    "response = requests.get(BASE_URL)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "for link in soup.find_all('a', href=True):\n",
    "    file_url = urljoin(BASE_URL, link['href'])\n",
    "    file_name = os.path.basename(link['href'])\n",
    "    ext = Path(file_name).suffix.lower()\n",
    "\n",
    "    if ext not in extensions and ext != '.doc':\n",
    "        continue\n",
    "\n",
    "    file_path = RESULTS_DIR / file_name\n",
    "    txt_path = RESULTS_DIR / (Path(file_name).stem + \".txt\")\n",
    "\n",
    "    # Skip if .txt already exists\n",
    "    if txt_path.exists():\n",
    "        print(f\"‚ö†Ô∏è Skipping (already converted): {txt_path.name}\")\n",
    "        continue\n",
    "\n",
    "    # Skip if raw file is already downloaded (.txt only)\n",
    "    if ext == '.txt' and file_path.exists():\n",
    "        print(f\"‚ö†Ô∏è Skipping (already downloaded): {file_path.name}\")\n",
    "        continue\n",
    "\n",
    "    # Download file\n",
    "    try:\n",
    "        file_data = requests.get(file_url)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(file_data.content)\n",
    "        print(f\"üì• Downloaded: {file_name}\")\n",
    "\n",
    "        # Convert if .docx\n",
    "        if ext == '.docx':\n",
    "            convert_docx_to_txt(file_path, txt_path)\n",
    "\n",
    "        elif ext == '.doc':\n",
    "            print(f\"‚ö†Ô∏è Skipping .doc file (not supported yet): {file_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error downloading or processing {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41cb899-ce64-48de-a20f-d43e3fa19fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934c56c-1df3-46de-956b-04f9073de3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d263d-0198-40e0-ae0a-57d9e823b33b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
